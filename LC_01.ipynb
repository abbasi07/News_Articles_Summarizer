{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Role Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme: interstellar travel\n",
      "Year: 3030\n",
      "AI-generated song title: \n",
      "\"Galactic Odyssey: Journey to 3030\"\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "# Initialize LLM\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "template = \"\"\"\n",
    "As a futuristic robot band conductor, I need you to help me come up with a song title.\n",
    "What's a cool song title for a song about {theme} in the year {year}?\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"theme\", \"year\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "# Create the LLMChain for the prompt\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "# Input data for the prompt\n",
    "input_data = {\"theme\": \"interstellar travel\", \"year\": \"3030\"}\n",
    "\n",
    "# Create LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the LLMChain to get the AI-generated song title\n",
    "response = chain.run(input_data)\n",
    "\n",
    "print(\"Theme: interstellar travel\")\n",
    "print(\"Year: 3030\")\n",
    "print(\"AI-generated song title:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color: purple\n",
      "Emotion:  royalty\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "examples = [\n",
    "    {\"color\": \"red\", \"emotion\": \"passion\"},\n",
    "    {\"color\": \"blue\", \"emotion\": \"serenity\"},\n",
    "    {\"color\": \"green\", \"emotion\": \"tranquility\"},\n",
    "]\n",
    "\n",
    "example_formatter_template = \"\"\"\n",
    "Color: {color}\n",
    "Emotion: {emotion}\\n\n",
    "\"\"\"\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"color\", \"emotion\"],\n",
    "    template=example_formatter_template,\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Here are some examples of colors and the emotions associated with them:\\n\\n\",\n",
    "    suffix=\"\\n\\nNow, given a new color, identify the emotion associated with it:\\n\\nColor: {input}\\nEmotion:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\",\n",
    ")\n",
    "\n",
    "formatted_prompt = few_shot_prompt.format(input=\"purple\")\n",
    "\n",
    "# Create the LLMChain for the prompt\n",
    "chain = LLMChain(llm=llm, prompt=PromptTemplate(template=formatted_prompt, input_variables=[]))\n",
    "\n",
    "# Run the LLMChain to get the AI-generated emotion associated with the input color\n",
    "response = chain.run({})\n",
    "\n",
    "print(\"Color: purple\")\n",
    "print(\"Emotion:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist: Albert Einstein\n",
      "Fact: \n",
      "Albert Einstein's theory of general relativity is a theory of gravity that explains how massive objects interact with each other and how they affect the fabric of space and time. According to this theory, gravity is not a force between masses, but rather a curvature of space and time caused by the presence of massive objects. This curvature is what causes objects to move towards each other, as if they were being pulled by a force. General relativity also predicts that the path of an object in space is affected by the presence of other massive objects, and that the passage of time is affected by the strength of gravity. This theory has been confirmed by numerous experiments and is considered one of the most important and influential theories in modern physics.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "# Prompt 1\n",
    "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
    "Answer: \"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# Prompt 2\n",
    "template_fact = \"\"\"Provide a brief description of {scientist}'s theory of general relativity.\n",
    "Answer: \"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Extract the scientist's name from the response\n",
    "scientist = response_question.strip()\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"scientist\": scientist}\n",
    "\n",
    "# Run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Scientist:\", scientist)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain of Thought Prompting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: What are some tips for improving communication skills?\n",
      "AI Response: Active listening, being clear and concise, and practicing empathy are all important skills for effective communication. Also, don't be afraid to ask for clarification or feedback to improve your communication.\n"
     ]
    }
   ],
   "source": [
    "from langchain import FewShotPromptTemplate, PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What's the secret to happiness?\",\n",
    "        \"answer\": \"Finding balance in life and learning to enjoy the small moments.\"\n",
    "    }, {\n",
    "        \"query\": \"How can I become more productive?\",\n",
    "        \"answer\": \"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
    "life coach. The assistant provides insightful and practical advice to the users' questions. Here are some\n",
    "examples: \n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Create the LLMChain for the few-shot prompt template\n",
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt_template)\n",
    "\n",
    "# Define the user query\n",
    "user_query = \"What are some tips for improving communication skills?\"\n",
    "\n",
    "# Run the LLMChain for the user query\n",
    "response = chain.run({\"query\": user_query})\n",
    "\n",
    "print(\"User Query:\", user_query)\n",
    "print(\"AI Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LC_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
